{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1ff6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.8 MB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: requests in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.8 MB 40.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200 kB 27.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/santosh/Anaconda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/santosh/Anaconda/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/santosh/Anaconda/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/santosh/Anaconda/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/santosh/Anaconda/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/santosh/Anaconda/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n"
     ]
    }
   ],
   "source": [
    "# Lighter version, no specific machine learning frameworks (like PyTorch or TensorFlow) are installed.\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61981a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[sentencepiece] in /home/santosh/Anaconda/lib/python3.9/site-packages (4.27.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers[sentencepiece]) (1.24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers[sentencepiece]) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers[sentencepiece]) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers[sentencepiece]) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers[sentencepiece]) (6.0)\n",
      "Requirement already satisfied: filelock in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers[sentencepiece]) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers[sentencepiece]) (0.13.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers[sentencepiece]) (21.3)\n",
      "Requirement already satisfied: requests in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers[sentencepiece]) (2.27.1)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<=3.20.2 in /home/santosh/Anaconda/lib/python3.9/site-packages (from transformers[sentencepiece]) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/santosh/Anaconda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers[sentencepiece]) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/santosh/Anaconda/lib/python3.9/site-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/santosh/Anaconda/lib/python3.9/site-packages (from requests->transformers[sentencepiece]) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/santosh/Anaconda/lib/python3.9/site-packages (from requests->transformers[sentencepiece]) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/santosh/Anaconda/lib/python3.9/site-packages (from requests->transformers[sentencepiece]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/santosh/Anaconda/lib/python3.9/site-packages (from requests->transformers[sentencepiece]) (2021.10.8)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "# Development version, comes with all the required dependencies for pretty much any imaginable use case\n",
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c88966",
   "metadata": {},
   "source": [
    "**Transformer, what can they do?**\n",
    "\n",
    "The most basic object in the ðŸ¤— Transformers library is the **pipeline()** function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an answer.\n",
    "\n",
    "**Preprocessing  -->  MODEL  --> Postprocessing**\n",
    "\n",
    "There are three main steps involved when you pass some text to a pipeline:\n",
    "\n",
    "=> The text is preprocessed into a format the model can understand.\n",
    "=> The preprocessed inputs are passed to the model.\n",
    "=> The predictions of the model are post-processed, so you can make sense of them.\n",
    "\n",
    "Some of the currently Available pipelines can be viewed at: https://huggingface.co/docs/transformers/main_classes/pipelines\n",
    "\n",
    "**Some of the NLP pipelines:**\n",
    "1) feature-extraction (get the vector representation of a text)\n",
    "\n",
    "2) fill-mask\n",
    "\n",
    "3) ner (named entity recognition)\n",
    "\n",
    "4) question-answering\n",
    "\n",
    "5) sentiment-analysis\n",
    "\n",
    "6) summarization\n",
    "\n",
    "7) text-generation\n",
    "\n",
    "8) translation\n",
    "\n",
    "9) zero-shot-classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a9bc6b",
   "metadata": {},
   "source": [
    "**ZERO-SHOT-CLASSIFICATION**\n",
    "\n",
    "Here we classify texts that haven't been labelled. This is a common scenario in real-world projects because annotating text is usually time-consuming and requires domain expertise.\n",
    "\n",
    "zero-shot-classification pipeline is very powerful: it allows you to specify which labels to use for the classification, so you donâ€™t have to rely on the labels of the pretrained model.\n",
    "\n",
    "Youâ€™ve already seen how the model can classify a sentence as positive or negative using those two labels â€” but it can also classify the text using any other set of labels you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba0cb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-07 17:12:05.221005: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-07 17:12:05.561163: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-07 17:12:05.561229: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-07 17:12:06.682841: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-07 17:12:06.682901: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-07 17:12:06.682908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
